The goal of this project is to use the Kindle Books dataset from Kaggle to predict the star ratings of Kindle books. The objective is to develop a predictive model that estimates a book’s star rating based on various features, including author, price, book length, number of reviews, and publisher. By identifying the key factors that influence reader satisfaction, this analysis can also provide prescriptive insights: libraries and bookstores can use the model to optimize book selection, pricing, and promotion strategies, prioritizing titles likely to receive higher ratings. This data-driven approach supports better decision-making, enhances reader engagement, and improves overall satisfaction. 

This project predicts the star rating of new books by authors who have published at least three titles on Amazon. I used a random 80/20 split by book title to create the training and test sets. 
During descriptive analysis, I found that avg_stars (the author’s average rating) is strongly positively correlated with stars. This relationship exists partly because many authors with only one book in the dataset have avg_stars equal to that book’s rating. To address this and prevent data leakage, I ensured that each title appears in only one dataset—either training or test.
The modeling methods include a baseline model, a simple linear model, a full linear model, and a pruned decision tree. I evaluated model performance using RMSE, R^2, and the train-test performance gap. I also performed 5-fold cross-validation on the full linear model to assess its stability and generalizability.

Building upon the predictive analysis—where the full linear regression model achieved the strongest performance (RMSE = 0.3553, R^2 = 0.4566)—this prescriptive analysis extends those insights to decision-making. The model uses linear programming to identify the optimal configuration of controllable variables to determine which Kindle titles to license and how many copies of each to purchase, in order to maximize predicted patron satisfaction (star_rating) while adhering to budgetary and policy constraints.

The results showed that the allocated budget of $95,000 was fully utilized across 760 distinct titles and 7,600 total licenses. The optimal solution favored purchasing multiple copies of high-value titles over expanding the number of distinct titles. 100% of the selected titles reached the maximum per-title cap of 10 licenses, confirming that this constraint was binding. The top 20 titles all had similarly high predicted star ratings, reflecting a relationship between predicted satisfaction and the allocation decisions. The model also satisfied the spend-floor constraints, ensuring sufficient investment per selected title.
